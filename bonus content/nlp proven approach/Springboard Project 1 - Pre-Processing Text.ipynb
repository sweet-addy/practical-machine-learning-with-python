{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!pip install nltk\n",
    "#have to install the 'en_core_web_sm' model below like this because something about Jupyter Notebook\n",
    "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.0/en_core_web_sm-2.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "#nlp = spacy.load('en_core', parse = True, tag=True, entity=True) (DJ'S code)\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, entity=True) (DJ's code)\n",
    "tokenizer = ToktokTokenizer()\n",
    "##needed to use the comment out line below to get the stopwords\n",
    "#nltk.download('stopwords') \n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove accented characters\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "#test the function with example\n",
    "remove_accented_chars('Sómě Áccěntěd těxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to expand contractions\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "#example\n",
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove special characters\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "#example\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", \n",
    "                          remove_digits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find stem words\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#example\n",
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for lemmatization\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "#example\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#example\n",
    "remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bringing it all together — Building a Text Normalizer\n",
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/adamj/Documents/Github/Springboard/Project/Books-for-Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir() #see files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open all books to be analyzed (10 bestsellers; 10 nonbestsellers)\n",
    "Beautiful_Disaster=open('Beautiful Disaster by Jamie McGuire_BS.txt',\"r\",encoding=\"utf8\")\n",
    "Breaching_His_Defenses=open('Breaching-His-Defenses by Allyson Lindt_NBS.txt',\"r\",encoding=\"utf8\")\n",
    "Desired=open('Desired by Alisa Woods_NBS.txt',\"r\",encoding=\"utf8\")\n",
    "Fearsome=open('Fearsome by S.A. Wolfe_NBS.txt',\"r\",encoding=\"utf8\")\n",
    "Fifty_Shades_Darker=open('Fifty Shades Darker by EL James_BS.txt',\"r\",encoding=\"utf8\")\n",
    "Fifty_Shades_of_Grey=open('Fifty Shades of Grey by EL James_BS.txt',\"r\",encoding=\"utf8\")\n",
    "Finding_Master_Right=open('Finding Master Right by Sparrow Beckett_NBS.txt',\"r\",encoding=\"utf8\")\n",
    "Healing_Her_Heart=open('Healing-Her-Heart by Laura Scott_NBS.txt',\"r\",encoding=\"utf8\")\n",
    "Hopeless=open('Hopeless by Colleen Hoover_BS.txt',\"r\",encoding=\"utf8\")\n",
    "Lilas_Loves=open(\"Lila's Loves by Laylah Roberts_NBS.txt\",\"r\",encoding=\"utf8\")\n",
    "Lolita=open(\"Lolita by Vladamir Norbakov_BS.txt\",\"r\",encoding=\"utf8\")\n",
    "Mademoiselle_at_Arms=open(\"Mademoiselle-At-Arms by Bailey Elizabeth_NBS.txt\",\"r\",encoding=\"utf8\")\n",
    "Me_Before_You=open(\"Me Before You by Jojo Moyes_BS.txt\",\"r\",encoding=\"utf8\")\n",
    "Mothers_Black_Book=open(\"Mother's-Black-Book by H.H. Fowler_NBS.txt\",\"r\",encoding=\"utf8\")\n",
    "Outlander=open(\"Outlander by Diana Gabaldon_BS.txt\",\"r\",encoding=\"utf8\")\n",
    "Taking_Chances=open('Taking-Chances by Ann Omasta_NBS.txt',\"r\",encoding=\"utf8\")\n",
    "The_Fault_in_Our_Stars=open('The Fault in Our Stars by John Green_BS.txt',\"r\",encoding=\"utf8\")\n",
    "The_Notebook=open('The Notebook by Nicholas Sparks_BS.txt',\"r\",encoding=\"utf8\")\n",
    "The_Time_Travelers_Wife=open(\"The Time Traveler's Wife by Audrey Niffenager_BS.txt\",\"r\",encoding=\"utf8\")\n",
    "The_Titan_Drowns_Time_Travel_Romance=open('The-Titan-Drowns-Time-Travel-Romance by Nyhs Glover_NBS.txt',\"r\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my arms she was always Lolita.\n",
      "\n",
      "\n",
      "\n",
      "Did she have a precursor? She did, indeed she did. In point of fact, there\n",
      "\n",
      "might have been no Lolita at all had I not loved, one summer, a certain initial\n",
      "\n",
      "girl—Child. In a princedom by the sea. Oh when? About as many years before Lolita was born as my age was that summer. You can always count on a murderer for\n",
      "\n",
      "a fancy prose style.\n",
      "\n",
      "\n",
      "\n",
      "Ladies and gentlemen of the jury, exhibit number one is what the seraphs, the mis—\n",
      "\n",
      "informed, simple, noble—winged seraphs, envied. Look at this tangle of thorns.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test code on one book\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())\n",
    "print(Lolita.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Beautiful Disaster by...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Breaching-His-Defense...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Desired by Alisa Wood...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Fearsome by S.A. Wolf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Fifty Shades Darker b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Fifty Shades of Grey ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Finding Master Right ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Healing-Her-Heart by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Hopeless by Colleen H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>&lt;_io.TextIOWrapper name=\"Lila's Loves by Layla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Lolita by Vladamir No...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Mademoiselle-At-Arms ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Me Before You by Jojo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>&lt;_io.TextIOWrapper name=\"Mother's-Black-Book b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Outlander by Diana Ga...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='Taking-Chances by Ann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='The Fault in Our Star...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='The Notebook by Nicho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>&lt;_io.TextIOWrapper name=\"The Time Traveler's W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>&lt;_io.TextIOWrapper name='The-Titan-Drowns-Time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Document  Category\n",
       "0   <_io.TextIOWrapper name='Beautiful Disaster by...         1\n",
       "1   <_io.TextIOWrapper name='Breaching-His-Defense...         0\n",
       "2   <_io.TextIOWrapper name='Desired by Alisa Wood...         0\n",
       "3   <_io.TextIOWrapper name='Fearsome by S.A. Wolf...         0\n",
       "4   <_io.TextIOWrapper name='Fifty Shades Darker b...         1\n",
       "5   <_io.TextIOWrapper name='Fifty Shades of Grey ...         1\n",
       "6   <_io.TextIOWrapper name='Finding Master Right ...         0\n",
       "7   <_io.TextIOWrapper name='Healing-Her-Heart by ...         0\n",
       "8   <_io.TextIOWrapper name='Hopeless by Colleen H...         1\n",
       "9   <_io.TextIOWrapper name=\"Lila's Loves by Layla...         0\n",
       "10  <_io.TextIOWrapper name='Lolita by Vladamir No...         1\n",
       "11  <_io.TextIOWrapper name='Mademoiselle-At-Arms ...         0\n",
       "12  <_io.TextIOWrapper name='Me Before You by Jojo...         1\n",
       "13  <_io.TextIOWrapper name=\"Mother's-Black-Book b...         0\n",
       "14  <_io.TextIOWrapper name='Outlander by Diana Ga...         1\n",
       "15  <_io.TextIOWrapper name='Taking-Chances by Ann...         0\n",
       "16  <_io.TextIOWrapper name='The Fault in Our Star...         1\n",
       "17  <_io.TextIOWrapper name='The Notebook by Nicho...         1\n",
       "18  <_io.TextIOWrapper name=\"The Time Traveler's W...         1\n",
       "19  <_io.TextIOWrapper name='The-Titan-Drowns-Time...         0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a list of all the books\n",
    "books_corpus=[Beautiful_Disaster,Breaching_His_Defenses,Desired,Fearsome,Fifty_Shades_Darker,Fifty_Shades_of_Grey,\n",
    "              Finding_Master_Right,Healing_Her_Heart,Hopeless,Lilas_Loves,Lolita,Mademoiselle_at_Arms,Me_Before_You,\n",
    "              Mothers_Black_Book,Outlander,Taking_Chances,The_Fault_in_Our_Stars,The_Notebook,The_Time_Travelers_Wife,\n",
    "              The_Titan_Drowns_Time_Travel_Romance]\n",
    "labels=[1,0,0,0,1,1,0,0,1,0,1,0,1,0,1,0,1,1,1,0]\n",
    "\n",
    "books_corpus_arr=np.array(books_corpus)\n",
    "corpus_df = pd.DataFrame({'Document': books_corpus_arr, \n",
    "                          'Category': labels})\n",
    "corpus_df = corpus_df[['Document', 'Category']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_io.TextIOWrapper name='Beautiful Disaster by Jamie McGuire_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Breaching-His-Defenses by Allyson Lindt_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Desired by Alisa Woods_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Fearsome by S.A. Wolfe_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Fifty Shades Darker by EL James_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Fifty Shades of Grey by EL James_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Finding Master Right by Sparrow Beckett_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Healing-Her-Heart by Laura Scott_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Hopeless by Colleen Hoover_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name=\"Lila's Loves by Laylah Roberts_NBS.txt\" mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Lolita by Vladamir Norbakov_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Mademoiselle-At-Arms by Bailey Elizabeth_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Me Before You by Jojo Moyes_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name=\"Mother's-Black-Book by H.H. Fowler_NBS.txt\" mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Outlander by Diana Gabaldon_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='Taking-Chances by Ann Omasta_NBS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='The Fault in Our Stars by John Green_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='The Notebook by Nicholas Sparks_BS.txt' mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name=\"The Time Traveler's Wife by Audrey Niffenager_BS.txt\" mode='r' encoding='utf8'>,\n",
       " <_io.TextIOWrapper name='The-Titan-Drowns-Time-Travel-Romance by Nyhs Glover_NBS.txt' mode='r' encoding='utf8'>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Beautiful_Disaster.close()\n",
    "Breaching_His_Defenses.close()\n",
    "Desired.close()\n",
    "Fearsome.close()\n",
    "Fifty_Shades_Darker.close()\n",
    "Fifty_Shades_of_Grey.close()\n",
    "Finding_Master_Right.close()\n",
    "Healing_Her_Heart.close()\n",
    "Hopeless.close()\n",
    "Lilas_Loves.close()\n",
    "Lolita.close()\n",
    "Mademoiselle_at_Arms.close()\n",
    "Me_Before_You.close()\n",
    "Mothers_Black_Book.close()\n",
    "Outlander.close()\n",
    "Taking_Chances.close()\n",
    "The_Fault_in_Our_Stars.close()\n",
    "The_Notebook.close()\n",
    "The_Time_Travelers_Wife.close()\n",
    "The_Titan_Drowns_Time_Travel_Romance.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
